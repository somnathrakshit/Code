{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_transfer",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/somnathrakshit/Code/blob/master/keras_transfer.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_j0PXmcCLEd9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b899689a-b97e-482a-f36a-5473ff788025"
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "# !rm -rf dogscats/\n",
        "# !kill -9 -1\n",
        "# !pip install -U -q PyDrive kaggle keras\n",
        "\n",
        "def download():\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "\n",
        "    # Authenticate and create the PyDrive client.\n",
        "    # This only needs to be done once per notebook.\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    # Download a file based on its file ID.\n",
        "    #\n",
        "    # A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "    file_id = '1uOHcurx42GonrO5xgwENMA3n2SfOZW2t'\n",
        "    file_name = 'data.zip'\n",
        "    print('Started Download')\n",
        "    downloaded = drive.CreateFile({'id': file_id})\n",
        "    downloaded.GetContentFile(file_name)\n",
        "    print('Download Complete')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  datalab  data.zip\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JkvkG5GzJuvj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download()\n",
        "# !unzip -q data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EL9BKSe2--wM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_height = 700\n",
        "img_width = 460"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MZnR334J_RM8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "#Load the VGG model\n",
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JDWDPj1g_svG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "f8f23e43-adbf-4c0c-d4f4-ab55756c289a"
      },
      "cell_type": "code",
      "source": [
        "# Freeze the layers except the last 4 layers\n",
        "for layer in vgg_conv.layers[:-4]:\n",
        "    layer.trainable = False\n",
        " \n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg_conv.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.topology.InputLayer object at 0x7f84848f1a90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8484891978> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847ecdcd30> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f84808a6c88> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f848091b240> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847fcc17b8> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f847fcd10f0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847fce7518> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847fc95278> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847fca90b8> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f847fc40080> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847fc6a5c0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847fbffe48> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847fbc04e0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f847fc2b978> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847fbd5278> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847fb825f8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f847fb942e8> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f847fb3ef98> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y2bv1X69IXz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2a863a4c-316a-4ff3-a151-c7290be5a209"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_path = 'data'\n",
        "\n",
        "# Change the batchsize according to your system RAM\n",
        "train_batchsize = 8\n",
        "val_batchsize = 8\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "      validation_split=0.2,\n",
        "#       rescale=1./255,\n",
        "#       rotation_range=20,\n",
        "#       width_shift_range=0.2,\n",
        "#       height_shift_range=0.2,\n",
        "#       horizontal_flip=True,\n",
        "#       fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=train_batchsize,\n",
        "    subset='training',\n",
        "    class_mode='categorical')\n",
        " \n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=val_batchsize,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6331 images belonging to 8 classes.\n",
            "Found 1578 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VJtJLYaXBpSs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "008c9247-c903-4ae1-95d5-c451568e0960"
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "# Create the model\n",
        "model = models.Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg_conv)\n",
        " \n",
        "# Add new layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(8, activation='softmax'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 21, 14, 512)       14714688  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 150528)            0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              154141696 \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 168,864,584\n",
            "Trainable params: 161,229,320\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RRjVFLcXItYM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "56b55873-09af-4bff-cc30-e5fcc701eabc"
      },
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=0.0001, momentum=0.9, decay=0.0, nesterov=False),\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples//train_generator.batch_size ,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples//validation_generator.batch_size,\n",
        "      verbose=1\n",
        ")\n",
        " \n",
        "# Save the model\n",
        "model.save('small_last4.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "791/791 [==============================] - 956s 1s/step - loss: 1.8925 - acc: 0.4122 - val_loss: 1.7021 - val_acc: 0.4308\n",
            "Epoch 2/30\n",
            "119/791 [===>..........................] - ETA: 11:09 - loss: 1.5639 - acc: 0.4601"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "211/791 [=======>......................] - ETA: 9:36 - loss: 1.5723 - acc: 0.4631"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bE_LZsz6I29c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}